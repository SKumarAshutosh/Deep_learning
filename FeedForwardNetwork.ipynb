{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPQr7Yh+HcqscXnLimDyscN",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SKumarAshutosh/Deep_learning/blob/main/FeedForwardNetwork.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Simpler analogy to explain the process of training a neural network and making predictions.\n",
        "\n",
        "**Imagine a Teacher and a Student:**\n",
        "\n",
        "1. **Training Data**: The teacher has a set of questions with their respective answers. The student tries to learn the pattern or logic behind those questions and answers.\n",
        "\n",
        "2. **Training the Model (Student Learning)**: The teacher gives the student many of these questions and checks the answers. If the student is wrong, the teacher corrects them. Over time, the student gets better and starts answering most questions correctly.\n",
        "\n",
        "3. **Testing the Model (Exam Time)**: Once the learning is done, the teacher gives the student new questions (ones they haven't seen before) to see if they truly understand. If the student performs well, it means they have not just memorized answers but have learned the underlying pattern.\n",
        "\n",
        "4. **Making Predictions (Real-world Questions)**: Now, imagine someone else comes with a new question for the student. Based on what the student learned, they will try to answer this new question.\n",
        "\n",
        "**Applying this to the Iris Dataset and FNN**:\n",
        "\n",
        "1. **Training Data**: We have measurements from many flowers and we know their species. This is like our set of questions with their answers.\n",
        "\n",
        "2. **Training the Model**: Our computer (like the student) tries to learn the relationship between the measurements and the species. We keep adjusting it until it gets most of them right.\n",
        "\n",
        "3. **Testing the Model**: We give the computer new flower measurements (ones it hasn't seen while learning) to see if it correctly identifies the species. This is like the exam to check if our computer really understands.\n",
        "\n",
        "4. **Making Predictions**: Now, if we find a new flower and measure it, we can ask the computer, \"Based on what you've learned, what species do you think this flower is?\" The computer will then give its best guess.\n",
        "\n",
        "In essence, we're teaching the computer to recognize patterns in data, much like how a student learns patterns in questions and answers. After \"learning,\" the computer can make educated guesses about new data it hasn't seen before."
      ],
      "metadata": {
        "id": "koelXcNlVghx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "## 1. Load the dataset:\n",
        "\n",
        "**Variables Introduced:**\n",
        "\n",
        "\n",
        "* iris: The dataset containing features and labels of the iris dataset.\n",
        "* X: The feature matrix containing measurements of iris flowers.\n",
        "* y: The target labels indicating the species of the iris flowers."
      ],
      "metadata": {
        "id": "CzGBDeF2G7xq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **1. Load the dataset**\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "Blchwy-HJkQj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Imports required modules.\n",
        "from sklearn import datasets\n",
        "from sklearn.preprocessing import OneHotEncoder"
      ],
      "metadata": {
        "id": "AITf_96sIoWy"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Loads the iris dataset\n",
        "#iris: Contains the dataset with features and labels of iris flowers.\n",
        "iris = datasets.load_iris()"
      ],
      "metadata": {
        "id": "6ihnDA5BIwhX"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "iris"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zCiIFIBCR7xo",
        "outputId": "e61d2e59-ecc2-4e9d-be35-0213ed709142"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'data': array([[5.1, 3.5, 1.4, 0.2],\n",
              "        [4.9, 3. , 1.4, 0.2],\n",
              "        [4.7, 3.2, 1.3, 0.2],\n",
              "        [4.6, 3.1, 1.5, 0.2],\n",
              "        [5. , 3.6, 1.4, 0.2],\n",
              "        [5.4, 3.9, 1.7, 0.4],\n",
              "        [4.6, 3.4, 1.4, 0.3],\n",
              "        [5. , 3.4, 1.5, 0.2],\n",
              "        [4.4, 2.9, 1.4, 0.2],\n",
              "        [4.9, 3.1, 1.5, 0.1],\n",
              "        [5.4, 3.7, 1.5, 0.2],\n",
              "        [4.8, 3.4, 1.6, 0.2],\n",
              "        [4.8, 3. , 1.4, 0.1],\n",
              "        [4.3, 3. , 1.1, 0.1],\n",
              "        [5.8, 4. , 1.2, 0.2],\n",
              "        [5.7, 4.4, 1.5, 0.4],\n",
              "        [5.4, 3.9, 1.3, 0.4],\n",
              "        [5.1, 3.5, 1.4, 0.3],\n",
              "        [5.7, 3.8, 1.7, 0.3],\n",
              "        [5.1, 3.8, 1.5, 0.3],\n",
              "        [5.4, 3.4, 1.7, 0.2],\n",
              "        [5.1, 3.7, 1.5, 0.4],\n",
              "        [4.6, 3.6, 1. , 0.2],\n",
              "        [5.1, 3.3, 1.7, 0.5],\n",
              "        [4.8, 3.4, 1.9, 0.2],\n",
              "        [5. , 3. , 1.6, 0.2],\n",
              "        [5. , 3.4, 1.6, 0.4],\n",
              "        [5.2, 3.5, 1.5, 0.2],\n",
              "        [5.2, 3.4, 1.4, 0.2],\n",
              "        [4.7, 3.2, 1.6, 0.2],\n",
              "        [4.8, 3.1, 1.6, 0.2],\n",
              "        [5.4, 3.4, 1.5, 0.4],\n",
              "        [5.2, 4.1, 1.5, 0.1],\n",
              "        [5.5, 4.2, 1.4, 0.2],\n",
              "        [4.9, 3.1, 1.5, 0.2],\n",
              "        [5. , 3.2, 1.2, 0.2],\n",
              "        [5.5, 3.5, 1.3, 0.2],\n",
              "        [4.9, 3.6, 1.4, 0.1],\n",
              "        [4.4, 3. , 1.3, 0.2],\n",
              "        [5.1, 3.4, 1.5, 0.2],\n",
              "        [5. , 3.5, 1.3, 0.3],\n",
              "        [4.5, 2.3, 1.3, 0.3],\n",
              "        [4.4, 3.2, 1.3, 0.2],\n",
              "        [5. , 3.5, 1.6, 0.6],\n",
              "        [5.1, 3.8, 1.9, 0.4],\n",
              "        [4.8, 3. , 1.4, 0.3],\n",
              "        [5.1, 3.8, 1.6, 0.2],\n",
              "        [4.6, 3.2, 1.4, 0.2],\n",
              "        [5.3, 3.7, 1.5, 0.2],\n",
              "        [5. , 3.3, 1.4, 0.2],\n",
              "        [7. , 3.2, 4.7, 1.4],\n",
              "        [6.4, 3.2, 4.5, 1.5],\n",
              "        [6.9, 3.1, 4.9, 1.5],\n",
              "        [5.5, 2.3, 4. , 1.3],\n",
              "        [6.5, 2.8, 4.6, 1.5],\n",
              "        [5.7, 2.8, 4.5, 1.3],\n",
              "        [6.3, 3.3, 4.7, 1.6],\n",
              "        [4.9, 2.4, 3.3, 1. ],\n",
              "        [6.6, 2.9, 4.6, 1.3],\n",
              "        [5.2, 2.7, 3.9, 1.4],\n",
              "        [5. , 2. , 3.5, 1. ],\n",
              "        [5.9, 3. , 4.2, 1.5],\n",
              "        [6. , 2.2, 4. , 1. ],\n",
              "        [6.1, 2.9, 4.7, 1.4],\n",
              "        [5.6, 2.9, 3.6, 1.3],\n",
              "        [6.7, 3.1, 4.4, 1.4],\n",
              "        [5.6, 3. , 4.5, 1.5],\n",
              "        [5.8, 2.7, 4.1, 1. ],\n",
              "        [6.2, 2.2, 4.5, 1.5],\n",
              "        [5.6, 2.5, 3.9, 1.1],\n",
              "        [5.9, 3.2, 4.8, 1.8],\n",
              "        [6.1, 2.8, 4. , 1.3],\n",
              "        [6.3, 2.5, 4.9, 1.5],\n",
              "        [6.1, 2.8, 4.7, 1.2],\n",
              "        [6.4, 2.9, 4.3, 1.3],\n",
              "        [6.6, 3. , 4.4, 1.4],\n",
              "        [6.8, 2.8, 4.8, 1.4],\n",
              "        [6.7, 3. , 5. , 1.7],\n",
              "        [6. , 2.9, 4.5, 1.5],\n",
              "        [5.7, 2.6, 3.5, 1. ],\n",
              "        [5.5, 2.4, 3.8, 1.1],\n",
              "        [5.5, 2.4, 3.7, 1. ],\n",
              "        [5.8, 2.7, 3.9, 1.2],\n",
              "        [6. , 2.7, 5.1, 1.6],\n",
              "        [5.4, 3. , 4.5, 1.5],\n",
              "        [6. , 3.4, 4.5, 1.6],\n",
              "        [6.7, 3.1, 4.7, 1.5],\n",
              "        [6.3, 2.3, 4.4, 1.3],\n",
              "        [5.6, 3. , 4.1, 1.3],\n",
              "        [5.5, 2.5, 4. , 1.3],\n",
              "        [5.5, 2.6, 4.4, 1.2],\n",
              "        [6.1, 3. , 4.6, 1.4],\n",
              "        [5.8, 2.6, 4. , 1.2],\n",
              "        [5. , 2.3, 3.3, 1. ],\n",
              "        [5.6, 2.7, 4.2, 1.3],\n",
              "        [5.7, 3. , 4.2, 1.2],\n",
              "        [5.7, 2.9, 4.2, 1.3],\n",
              "        [6.2, 2.9, 4.3, 1.3],\n",
              "        [5.1, 2.5, 3. , 1.1],\n",
              "        [5.7, 2.8, 4.1, 1.3],\n",
              "        [6.3, 3.3, 6. , 2.5],\n",
              "        [5.8, 2.7, 5.1, 1.9],\n",
              "        [7.1, 3. , 5.9, 2.1],\n",
              "        [6.3, 2.9, 5.6, 1.8],\n",
              "        [6.5, 3. , 5.8, 2.2],\n",
              "        [7.6, 3. , 6.6, 2.1],\n",
              "        [4.9, 2.5, 4.5, 1.7],\n",
              "        [7.3, 2.9, 6.3, 1.8],\n",
              "        [6.7, 2.5, 5.8, 1.8],\n",
              "        [7.2, 3.6, 6.1, 2.5],\n",
              "        [6.5, 3.2, 5.1, 2. ],\n",
              "        [6.4, 2.7, 5.3, 1.9],\n",
              "        [6.8, 3. , 5.5, 2.1],\n",
              "        [5.7, 2.5, 5. , 2. ],\n",
              "        [5.8, 2.8, 5.1, 2.4],\n",
              "        [6.4, 3.2, 5.3, 2.3],\n",
              "        [6.5, 3. , 5.5, 1.8],\n",
              "        [7.7, 3.8, 6.7, 2.2],\n",
              "        [7.7, 2.6, 6.9, 2.3],\n",
              "        [6. , 2.2, 5. , 1.5],\n",
              "        [6.9, 3.2, 5.7, 2.3],\n",
              "        [5.6, 2.8, 4.9, 2. ],\n",
              "        [7.7, 2.8, 6.7, 2. ],\n",
              "        [6.3, 2.7, 4.9, 1.8],\n",
              "        [6.7, 3.3, 5.7, 2.1],\n",
              "        [7.2, 3.2, 6. , 1.8],\n",
              "        [6.2, 2.8, 4.8, 1.8],\n",
              "        [6.1, 3. , 4.9, 1.8],\n",
              "        [6.4, 2.8, 5.6, 2.1],\n",
              "        [7.2, 3. , 5.8, 1.6],\n",
              "        [7.4, 2.8, 6.1, 1.9],\n",
              "        [7.9, 3.8, 6.4, 2. ],\n",
              "        [6.4, 2.8, 5.6, 2.2],\n",
              "        [6.3, 2.8, 5.1, 1.5],\n",
              "        [6.1, 2.6, 5.6, 1.4],\n",
              "        [7.7, 3. , 6.1, 2.3],\n",
              "        [6.3, 3.4, 5.6, 2.4],\n",
              "        [6.4, 3.1, 5.5, 1.8],\n",
              "        [6. , 3. , 4.8, 1.8],\n",
              "        [6.9, 3.1, 5.4, 2.1],\n",
              "        [6.7, 3.1, 5.6, 2.4],\n",
              "        [6.9, 3.1, 5.1, 2.3],\n",
              "        [5.8, 2.7, 5.1, 1.9],\n",
              "        [6.8, 3.2, 5.9, 2.3],\n",
              "        [6.7, 3.3, 5.7, 2.5],\n",
              "        [6.7, 3. , 5.2, 2.3],\n",
              "        [6.3, 2.5, 5. , 1.9],\n",
              "        [6.5, 3. , 5.2, 2. ],\n",
              "        [6.2, 3.4, 5.4, 2.3],\n",
              "        [5.9, 3. , 5.1, 1.8]]),\n",
              " 'target': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
              "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
              "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]),\n",
              " 'frame': None,\n",
              " 'target_names': array(['setosa', 'versicolor', 'virginica'], dtype='<U10'),\n",
              " 'DESCR': '.. _iris_dataset:\\n\\nIris plants dataset\\n--------------------\\n\\n**Data Set Characteristics:**\\n\\n    :Number of Instances: 150 (50 in each of three classes)\\n    :Number of Attributes: 4 numeric, predictive attributes and the class\\n    :Attribute Information:\\n        - sepal length in cm\\n        - sepal width in cm\\n        - petal length in cm\\n        - petal width in cm\\n        - class:\\n                - Iris-Setosa\\n                - Iris-Versicolour\\n                - Iris-Virginica\\n                \\n    :Summary Statistics:\\n\\n    ============== ==== ==== ======= ===== ====================\\n                    Min  Max   Mean    SD   Class Correlation\\n    ============== ==== ==== ======= ===== ====================\\n    sepal length:   4.3  7.9   5.84   0.83    0.7826\\n    sepal width:    2.0  4.4   3.05   0.43   -0.4194\\n    petal length:   1.0  6.9   3.76   1.76    0.9490  (high!)\\n    petal width:    0.1  2.5   1.20   0.76    0.9565  (high!)\\n    ============== ==== ==== ======= ===== ====================\\n\\n    :Missing Attribute Values: None\\n    :Class Distribution: 33.3% for each of 3 classes.\\n    :Creator: R.A. Fisher\\n    :Donor: Michael Marshall (MARSHALL%PLU@io.arc.nasa.gov)\\n    :Date: July, 1988\\n\\nThe famous Iris database, first used by Sir R.A. Fisher. The dataset is taken\\nfrom Fisher\\'s paper. Note that it\\'s the same as in R, but not as in the UCI\\nMachine Learning Repository, which has two wrong data points.\\n\\nThis is perhaps the best known database to be found in the\\npattern recognition literature.  Fisher\\'s paper is a classic in the field and\\nis referenced frequently to this day.  (See Duda & Hart, for example.)  The\\ndata set contains 3 classes of 50 instances each, where each class refers to a\\ntype of iris plant.  One class is linearly separable from the other 2; the\\nlatter are NOT linearly separable from each other.\\n\\n.. topic:: References\\n\\n   - Fisher, R.A. \"The use of multiple measurements in taxonomic problems\"\\n     Annual Eugenics, 7, Part II, 179-188 (1936); also in \"Contributions to\\n     Mathematical Statistics\" (John Wiley, NY, 1950).\\n   - Duda, R.O., & Hart, P.E. (1973) Pattern Classification and Scene Analysis.\\n     (Q327.D83) John Wiley & Sons.  ISBN 0-471-22361-1.  See page 218.\\n   - Dasarathy, B.V. (1980) \"Nosing Around the Neighborhood: A New System\\n     Structure and Classification Rule for Recognition in Partially Exposed\\n     Environments\".  IEEE Transactions on Pattern Analysis and Machine\\n     Intelligence, Vol. PAMI-2, No. 1, 67-71.\\n   - Gates, G.W. (1972) \"The Reduced Nearest Neighbor Rule\".  IEEE Transactions\\n     on Information Theory, May 1972, 431-433.\\n   - See also: 1988 MLC Proceedings, 54-64.  Cheeseman et al\"s AUTOCLASS II\\n     conceptual clustering system finds 3 classes in the data.\\n   - Many, many more ...',\n",
              " 'feature_names': ['sepal length (cm)',\n",
              "  'sepal width (cm)',\n",
              "  'petal length (cm)',\n",
              "  'petal width (cm)'],\n",
              " 'filename': 'iris.csv',\n",
              " 'data_module': 'sklearn.datasets.data'}"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Extracts the feature data from the iris dataset.\n",
        "#X: The feature matrix containing measurements of iris flowers.\n",
        "X = iris.data\n"
      ],
      "metadata": {
        "id": "vfOsYuhrHwBU"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Extracts target labels and reshapes them into a column vector.\n",
        "#y: The target labels indicating the iris flower species.\n",
        "y = iris.target.reshape(-1, 1)\n"
      ],
      "metadata": {
        "id": "lgQRFVe-JItU"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q. Why reshape with (-1, 1)?**\n",
        "\n",
        "reshape(-1, 1) means to reshape the data such that it has many rows as needed to maintain the number of elements and exactly one column. This is used to convert the flat array of target labels into a column vector."
      ],
      "metadata": {
        "id": "si8Wc89mP4SP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#One-hot encodes the target labels.\n",
        "# encoder: Instance of OneHotEncoder.\n",
        "# y_onehot: One-hot encoded target labels.\n",
        "encoder = OneHotEncoder(sparse=False)\n",
        "y_onehot = encoder.fit_transform(y)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K4uWp3DpJSXN",
        "outputId": "605ead58-e5f7-44f4-c3e0-a7fadcb743f4"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/preprocessing/_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q1. Why the need for one-hot encoding?**\n",
        "\n",
        "The iris dataset contains three classes: Setosa, Versicolour, and Virginica. These are represented as 0, 1, and 2 in the target array. For a multi-class classification using neural networks, it's often recommended to use one-hot encoding to represent class labels. One-hot encoding transforms categorical data into a format that can be more easily understood by the model, by representing each class with a binary vector."
      ],
      "metadata": {
        "id": "1fZ2zEajPa_X"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q. What is sparse and why is it False?**\n",
        "\n",
        "In OneHotEncoder, the sparse argument determines if the returned array should be a sparse matrix or a dense numpy array. sparse=False means we get a dense array, which is easier to work with in this context."
      ],
      "metadata": {
        "id": "Yx2Zaer6QLjX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **2. Split the dataset into training and testing sets**\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "D6FIYwk2JuAI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Imports the module to split datasets.\n",
        "from sklearn.model_selection import train_test_split\n"
      ],
      "metadata": {
        "id": "NLV_unYiJdiG"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Splits the dataset into training and testing subsets.\n",
        "# X_train, X_test: Training and testing feature matrices.\n",
        "# y_train, y_test: Training and testing target matrices\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y_onehot, test_size=0.2, random_state=42)\n"
      ],
      "metadata": {
        "id": "w4ArTx_2J8jw"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q Why random_state=42?**\n",
        "\n",
        "The random_state is a seed for the random number generator. By setting it to a fixed value (like 42), the train/test split will always be deterministic. This ensures that the results are reproducible across different runs."
      ],
      "metadata": {
        "id": "d6_ck-G8QnAh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **3. Build the feed-forward neural network:**\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "c3xtYfNSKOCw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Imports required TensorFlow and Keras modules.\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n"
      ],
      "metadata": {
        "id": "WA8hMK8HKGr3"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Initializes a linear stack of layers for the neural network.\n",
        "#model: The neural network model.\n",
        "model = Sequential()\n"
      ],
      "metadata": {
        "id": "lbS4VGSiKTw9"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Sequential():** This is used to initialize a linear stack of network layers. It allows you to build a model layer by layer.\n",
        "\n",
        "Dense: This is the layer type. Dense is a standard layer type that works for most cases. In a dense layer, all nodes in the previous layer connect to the nodes in the current layer.\n",
        "\n",
        "The first parameter, 10, is the number of neurons/nodes the layer has. For the input layer, you must also define the input_dim parameter, specifying the number of inputs (in this case, 4 inputs for the Iris dataset).\n",
        "\n",
        "activation: This is the activation function for the layer. The activation function decides whether a neuron should be activated based on the weighted sum. Here, we're using relu (Rectified Linear Activation) for our hidden layer and softmax for our output layer because it's a multi-class classification problem."
      ],
      "metadata": {
        "id": "-DtZ3ToJSmKu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Adds an input and hidden layer with 10 nodes and a ReLU activation function.\n",
        "model.add(Dense(10, input_dim=4, activation='relu'))\n"
      ],
      "metadata": {
        "id": "5HO1eb_UKnmR"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Why is the input dimension 4?**\n",
        "\n",
        "The iris dataset has 4 features (sepal length, sepal width, petal length, petal width) for each data point. Hence, the input dimension is set to 4."
      ],
      "metadata": {
        "id": "ILFtwRxNQwqE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Adds an output layer with 3 nodes (one for each iris species) and a softmax activation function.\n",
        "model.add(Dense(3, activation='softmax'))\n"
      ],
      "metadata": {
        "id": "Wqf7NXvqKucE"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q Why use ReLU for the first activation and softmax for the second?**\n",
        "\n",
        "ReLU (Rectified Linear Unit): It's a commonly used activation function in hidden layers because it introduces non-linearity without being computationally expensive.\n",
        "\n",
        "Softmax: It's used in the output layer of multi-class classification tasks. It converts the raw output values (logits) from the network into probability distributions over the classes."
      ],
      "metadata": {
        "id": "lb3JgSRkREbE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **4. Compile the model:**"
      ],
      "metadata": {
        "id": "X4Rev58TK_Ox"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Configures the model for training by setting the optimizer, loss function, and evaluation metric.\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n"
      ],
      "metadata": {
        "id": "9duYihNTK6MS"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Why choose the Adam optimizer and categorical_crossentropy loss?\n",
        "\n",
        "Adam optimizer: Combines the best properties of the AdaGrad and RMSprop algorithms to provide an optimization algorithm that can handle sparse gradients on noisy problems. It's computationally efficient and has little memory requirement.\n",
        "categorical_crossentropy loss: It's the recommended loss for multi-class classification problems. It measures the difference between the true labels and the predicted probabilities."
      ],
      "metadata": {
        "id": "mvorwYMMRWCH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **5. Train the model:**"
      ],
      "metadata": {
        "id": "-JSAj2HNLQ31"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Trains the model for 50 epochs using the training data and validates using the testing data.\n",
        "#history: Contains the training history, like loss and accuracy values at each epoch.\n",
        "history = model.fit(X_train, y_train, epochs=50, batch_size=10, validation_data=(X_test, y_test))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lh7MZfyFLM4f",
        "outputId": "6550b7c5-fe84-405c-aef1-6061e95e2518"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "12/12 [==============================] - 1s 24ms/step - loss: 1.8915 - accuracy: 0.3333 - val_loss: 1.7916 - val_accuracy: 0.3333\n",
            "Epoch 2/50\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 1.6454 - accuracy: 0.3333 - val_loss: 1.5711 - val_accuracy: 0.3333\n",
            "Epoch 3/50\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 1.4494 - accuracy: 0.3333 - val_loss: 1.3957 - val_accuracy: 0.3333\n",
            "Epoch 4/50\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 1.3023 - accuracy: 0.3333 - val_loss: 1.2618 - val_accuracy: 0.3333\n",
            "Epoch 5/50\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 1.1840 - accuracy: 0.3333 - val_loss: 1.1645 - val_accuracy: 0.3333\n",
            "Epoch 6/50\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 1.1004 - accuracy: 0.3333 - val_loss: 1.0842 - val_accuracy: 0.3333\n",
            "Epoch 7/50\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 1.0307 - accuracy: 0.3500 - val_loss: 1.0254 - val_accuracy: 0.3667\n",
            "Epoch 8/50\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.9780 - accuracy: 0.3917 - val_loss: 0.9669 - val_accuracy: 0.4333\n",
            "Epoch 9/50\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 0.9325 - accuracy: 0.4583 - val_loss: 0.9290 - val_accuracy: 0.5000\n",
            "Epoch 10/50\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.9009 - accuracy: 0.5667 - val_loss: 0.8975 - val_accuracy: 0.6000\n",
            "Epoch 11/50\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.8748 - accuracy: 0.6833 - val_loss: 0.8684 - val_accuracy: 0.8333\n",
            "Epoch 12/50\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.8501 - accuracy: 0.7750 - val_loss: 0.8456 - val_accuracy: 0.8333\n",
            "Epoch 13/50\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.8305 - accuracy: 0.8000 - val_loss: 0.8272 - val_accuracy: 0.8333\n",
            "Epoch 14/50\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.8115 - accuracy: 0.8000 - val_loss: 0.8061 - val_accuracy: 0.8000\n",
            "Epoch 15/50\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.7944 - accuracy: 0.8250 - val_loss: 0.7892 - val_accuracy: 0.8000\n",
            "Epoch 16/50\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.7777 - accuracy: 0.8167 - val_loss: 0.7738 - val_accuracy: 0.8000\n",
            "Epoch 17/50\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.7635 - accuracy: 0.8167 - val_loss: 0.7607 - val_accuracy: 0.8333\n",
            "Epoch 18/50\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.7491 - accuracy: 0.8167 - val_loss: 0.7427 - val_accuracy: 0.8333\n",
            "Epoch 19/50\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.7346 - accuracy: 0.8250 - val_loss: 0.7278 - val_accuracy: 0.8333\n",
            "Epoch 20/50\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.7207 - accuracy: 0.8167 - val_loss: 0.7143 - val_accuracy: 0.8333\n",
            "Epoch 21/50\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.7078 - accuracy: 0.8250 - val_loss: 0.7024 - val_accuracy: 0.8333\n",
            "Epoch 22/50\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.6951 - accuracy: 0.8333 - val_loss: 0.6895 - val_accuracy: 0.8333\n",
            "Epoch 23/50\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.6842 - accuracy: 0.8167 - val_loss: 0.6752 - val_accuracy: 0.8333\n",
            "Epoch 24/50\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.6714 - accuracy: 0.8083 - val_loss: 0.6650 - val_accuracy: 0.8333\n",
            "Epoch 25/50\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.6655 - accuracy: 0.8333 - val_loss: 0.6579 - val_accuracy: 0.8333\n",
            "Epoch 26/50\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.6500 - accuracy: 0.8417 - val_loss: 0.6448 - val_accuracy: 0.8333\n",
            "Epoch 27/50\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.6403 - accuracy: 0.8333 - val_loss: 0.6293 - val_accuracy: 0.8000\n",
            "Epoch 28/50\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.6301 - accuracy: 0.8083 - val_loss: 0.6203 - val_accuracy: 0.8333\n",
            "Epoch 29/50\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.6213 - accuracy: 0.7917 - val_loss: 0.6107 - val_accuracy: 0.8333\n",
            "Epoch 30/50\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.6111 - accuracy: 0.8000 - val_loss: 0.6009 - val_accuracy: 0.8333\n",
            "Epoch 31/50\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.6028 - accuracy: 0.8250 - val_loss: 0.5939 - val_accuracy: 0.8333\n",
            "Epoch 32/50\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.5940 - accuracy: 0.8333 - val_loss: 0.5831 - val_accuracy: 0.8333\n",
            "Epoch 33/50\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.5866 - accuracy: 0.7917 - val_loss: 0.5735 - val_accuracy: 0.8333\n",
            "Epoch 34/50\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.5786 - accuracy: 0.8417 - val_loss: 0.5699 - val_accuracy: 0.8333\n",
            "Epoch 35/50\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.5703 - accuracy: 0.8500 - val_loss: 0.5605 - val_accuracy: 0.8333\n",
            "Epoch 36/50\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.5628 - accuracy: 0.8417 - val_loss: 0.5523 - val_accuracy: 0.8333\n",
            "Epoch 37/50\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.5576 - accuracy: 0.8250 - val_loss: 0.5451 - val_accuracy: 0.8333\n",
            "Epoch 38/50\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.5494 - accuracy: 0.8333 - val_loss: 0.5376 - val_accuracy: 0.8333\n",
            "Epoch 39/50\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.5428 - accuracy: 0.8333 - val_loss: 0.5310 - val_accuracy: 0.8333\n",
            "Epoch 40/50\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.5413 - accuracy: 0.8000 - val_loss: 0.5218 - val_accuracy: 0.8000\n",
            "Epoch 41/50\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.5308 - accuracy: 0.8417 - val_loss: 0.5194 - val_accuracy: 0.8333\n",
            "Epoch 42/50\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.5252 - accuracy: 0.8417 - val_loss: 0.5139 - val_accuracy: 0.8333\n",
            "Epoch 43/50\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.5211 - accuracy: 0.8583 - val_loss: 0.5110 - val_accuracy: 0.9000\n",
            "Epoch 44/50\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.5151 - accuracy: 0.8667 - val_loss: 0.5038 - val_accuracy: 0.8333\n",
            "Epoch 45/50\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.5101 - accuracy: 0.8500 - val_loss: 0.4944 - val_accuracy: 0.8667\n",
            "Epoch 46/50\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.5045 - accuracy: 0.8417 - val_loss: 0.4892 - val_accuracy: 0.8667\n",
            "Epoch 47/50\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.5013 - accuracy: 0.8417 - val_loss: 0.4868 - val_accuracy: 0.8333\n",
            "Epoch 48/50\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.4954 - accuracy: 0.8417 - val_loss: 0.4798 - val_accuracy: 0.8667\n",
            "Epoch 49/50\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.4906 - accuracy: 0.8500 - val_loss: 0.4747 - val_accuracy: 0.8667\n",
            "Epoch 50/50\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4872 - accuracy: 0.8583 - val_loss: 0.4726 - val_accuracy: 0.8333\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q Why is epochs 50 and batch_size 10?**\n",
        "\n",
        "These are hyperparameters. epochs represents how many times the dataset will be passed forward and backward through the network.\n",
        "\n",
        "batch_size is the number of training examples used in one iteration. The chosen values are just starting points and might not be optimal; in practice, these values should be tuned for best performance."
      ],
      "metadata": {
        "id": "vrdVWvvsReu1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **6. Evaluate the model:**"
      ],
      "metadata": {
        "id": "vR749ILeM7Gk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Evaluates the model's performance on the test data.\n",
        "# loss: The loss value of the model on the test data.\n",
        "# accuracy: The accuracy of the model on the test data.\n",
        "loss, accuracy = model.evaluate(X_test, y_test)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0dfUgKUFLjyr",
        "outputId": "ccb0881c-ca59-47a9-ac87-2205a6b59d4a"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 239ms/step - loss: 0.4726 - accuracy: 0.8333\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Prints the loss and accuracy of the model on the test dataset.\n",
        "print(f\"Test Loss: {loss}\")\n",
        "print(f\"Test Accuracy: {accuracy}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0ptN3gWiNIzT",
        "outputId": "7b964d2e-a7e4-45ab-9cc9-3086f86e93e9"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Loss: 0.47258517146110535\n",
            "Test Accuracy: 0.8333333134651184\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q Why consider only accuracy in metrics?**\n",
        "\n",
        "Accuracy is a straightforward metric for classification problems. It gives a general idea of how well the model is performing. Depending on the problem, other metrics (like precision, recall, F1-score) might also be relevant. In this simple example, accuracy suffices to demonstrate model performance."
      ],
      "metadata": {
        "id": "qSSa-H-qRvBJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q. How is loss and accuracy calculated?**\n",
        "\n",
        "Loss: Represents how far the predictions of the model are from the true values. The categorical_crossentropy loss is commonly used for multi-class classification. It quantifies the difference between the predicted probability and the true class.\n",
        "\n",
        "\n",
        "Accuracy: It's a metric that calculates the proportion of correctly predicted classification outcomes in the dataset. For each prediction, if the maximum index in the predicted vector matches the maximum index in the true vector, then it's considered a correct prediction."
      ],
      "metadata": {
        "id": "kmdi1BHSPoHc"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "IOqmauw8NReM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Certainly! The ultimate goal of training a neural network, or any machine learning model for that matter, is to make predictions on new, unseen data. Let me break it down:\n",
        "\n",
        "**Purpose of Training a Neural Network:**\n",
        "\n",
        "1. **Modeling Relationships**: Neural networks, including FNNs, model the relationship between input features and target outputs. This modeling is learned from the provided training data.\n",
        "\n",
        "2. **Generalization**: While the immediate goal is to perform well on the training data, the real value of a trained model lies in its ability to generalize to new, unseen data. By splitting the dataset into training and testing sets, we can evaluate how well our model is likely to perform on data it hasn't seen before.\n",
        "\n",
        "3. **Decision Making**: Once trained, neural networks can help in decision-making processes by predicting outcomes based on new input data.\n",
        "\n",
        "Now, after training an FNN on the Iris dataset, you would typically want to use it to make predictions:\n",
        "\n",
        "**Making Predictions:**\n",
        "\n",
        "1. **Prepare New Data**: Let's assume you have measurements from a new flower and you want to predict its species using your trained model:\n",
        "\n",
        "```python\n",
        "# Example: New flower measurements\n",
        "new_data = [[5.1, 3.5, 1.4, 0.2]]  # Example data (sepal length, sepal width, petal length, petal width)\n",
        "```\n",
        "\n",
        "2. **Predict the Species**:\n",
        "\n",
        "```python\n",
        "predictions = model.predict(new_data)\n",
        "predicted_class = np.argmax(predictions, axis=1)\n",
        "```\n",
        "\n",
        "`model.predict()` will provide you with the probabilities for each class (species, in this case). Using `np.argmax()`, you can find out which class has the highest probability.\n",
        "\n",
        "3. **Interpret the Prediction**:\n",
        "\n",
        "```python\n",
        "iris_species = ['setosa', 'versicolor', 'virginica']\n",
        "print(f\"The predicted species for the new flower is: {iris_species[predicted_class[0]]}\")\n",
        "```\n",
        "\n",
        "To summarize, the purpose of training the FNN on the Iris dataset is to create a model that can predict the species of iris flowers based on their measurements. After training, you can use this model to predict the species of new flowers, assisting in classification tasks. This is a simplified example, but the principles apply to more complex datasets and problems: you train on known data to make predictions on unknown data."
      ],
      "metadata": {
        "id": "XaPah8obUl7r"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "u1yFmCeTXpTN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Feed-Forward Neural Networks (FNN) or Multi-layer Perceptrons (MLP) can be applied to a wide range of datasets, but there are some general characteristics and considerations:\n",
        "\n",
        "1. **Numerical Data**: FNNs work with numerical data. If your dataset has categorical data, you'll need to encode it into a numerical form, e.g., using one-hot encoding, ordinal encoding, etc.\n",
        "\n",
        "2. **Size of the Dataset**: FNNs have multiple parameters, and to train them effectively, you typically need a relatively large dataset. Small datasets might lead to overfitting, where the model performs well on the training data but poorly on unseen data.\n",
        "\n",
        "3. **Features and Complexity**:\n",
        "    - FNNs can handle datasets with many features or dimensions. However, the more features you have, the more complex (i.e., having more neurons or layers) your network might need to be.\n",
        "    - It's essential to scale or normalize features, especially if they have different units or scales. Common methods include Min-Max scaling and Standard (Z-score) normalization.\n",
        "\n",
        "4. **Task Type**:\n",
        "    - **Classification**: If you're categorizing data into classes, you'll need labeled data where each input has a corresponding class label. The output layer would typically use a softmax activation function for multi-class classification, and a sigmoid for binary classification.\n",
        "    - **Regression**: If you're predicting a continuous value, your dataset should have corresponding numerical targets. The output layer typically doesn't have an activation function, or it might use a linear activation function.\n",
        "\n",
        "5. **Consistency and Quality**:\n",
        "    - The dataset should be consistent. Anomalies, outliers, or noise can affect the performance of the FNN.\n",
        "    - Missing values need to be addressed before training, either by imputation or by removing data points with missing values.\n",
        "\n",
        "6. **Balanced Classes (for Classification)**: If one class has significantly more examples than another, the model might become biased towards the majority class. Techniques like oversampling, undersampling, or using synthetic data can help balance the classes.\n",
        "\n",
        "7. **Time-Series or Sequential Data Limitation**: While FNNs can handle time-series data, they don't inherently understand the sequence or time aspect of the data. Recurrent Neural Networks (RNNs) or Long Short-Term Memory networks (LSTMs) are more suited for such data.\n",
        "\n",
        "In summary, while FNNs are versatile and can handle a wide variety of datasets, the data needs to be preprocessed and structured correctly. The nature and quality of your dataset, along with the problem at hand (classification vs. regression), will dictate the architecture and complexity of your FNN."
      ],
      "metadata": {
        "id": "qjRDh8eHXtsB"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_0DsGU52Um1A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Test the knowledge\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "LRvWMA7NW-9n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install kaggle\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7G15LU_yXC_N",
        "outputId": "5b2eae2c-dc85-490e-c20b-0fa0e3b88e1b"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: kaggle in /usr/local/lib/python3.10/dist-packages (1.5.16)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.10/dist-packages (from kaggle) (1.16.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from kaggle) (2023.7.22)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.10/dist-packages (from kaggle) (2.8.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from kaggle) (2.31.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from kaggle) (4.66.1)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.10/dist-packages (from kaggle) (8.0.1)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.10/dist-packages (from kaggle) (2.0.6)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.10/dist-packages (from kaggle) (6.0.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.10/dist-packages (from bleach->kaggle) (0.5.1)\n",
            "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.10/dist-packages (from python-slugify->kaggle) (1.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->kaggle) (3.3.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->kaggle) (3.4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.upload()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        },
        "id": "W8neB-wPXKwP",
        "outputId": "08e5cf97-5a48-4eae-d2e5-882ba758d7e1"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-769abfd4-cfb1-492f-990e-25c675e73166\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-769abfd4-cfb1-492f-990e-25c675e73166\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving kaggle.json to kaggle.json\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'kaggle.json': b'{\"username\":\"akashutosh09\",\"key\":\"f3be8e4efaa13164998ccd39f480d0d7\"}'}"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q kaggle\n"
      ],
      "metadata": {
        "id": "Ufi4oeqFX3ll"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir -p ~/.kaggle\n",
        "!cp kaggle.json ~/.kaggle/\n",
        "!chmod 600 ~/.kaggle/kaggle.json\n"
      ],
      "metadata": {
        "id": "JR3-0KqVYkmn"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!kaggle datasets download -d abhishek14398/salary-dataset-simple-linear-regression"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A5kmGzEaYwJD",
        "outputId": "c7925f48-0c7a-4c98-cea4-08362fb3b2a1"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading salary-dataset-simple-linear-regression.zip to /content\n",
            "\r  0% 0.00/457 [00:00<?, ?B/s]\n",
            "\r100% 457/457 [00:00<00:00, 1.21MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip salary-dataset-simple-linear-regression.zip\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aV3S741NZPY4",
        "outputId": "e76841d0-e382-4adc-d7d3-c82936855b66"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  salary-dataset-simple-linear-regression.zip\n",
            "  inflating: Salary_dataset.csv      \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# importing libriries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n"
      ],
      "metadata": {
        "id": "DfeGrWRMZUQt"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "salary_dataset = pd.read_csv(\"./Salary_dataset.csv\")"
      ],
      "metadata": {
        "id": "Rcy7iHu5bSKc"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "salary_dataset.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "YpxGFAwabsAv",
        "outputId": "d0f60340-b58a-4587-ac95-b4fc4ae6a904"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   Unnamed: 0  YearsExperience   Salary\n",
              "0           0              1.2  39344.0\n",
              "1           1              1.4  46206.0\n",
              "2           2              1.6  37732.0\n",
              "3           3              2.1  43526.0\n",
              "4           4              2.3  39892.0"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-f4343002-5d32-49c7-af51-89493b94a8c9\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>YearsExperience</th>\n",
              "      <th>Salary</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>1.2</td>\n",
              "      <td>39344.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>1.4</td>\n",
              "      <td>46206.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>1.6</td>\n",
              "      <td>37732.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>2.1</td>\n",
              "      <td>43526.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>2.3</td>\n",
              "      <td>39892.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f4343002-5d32-49c7-af51-89493b94a8c9')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-f4343002-5d32-49c7-af51-89493b94a8c9 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-f4343002-5d32-49c7-af51-89493b94a8c9');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-3cdcdee5-951a-4ef0-9d13-604e88d25d1d\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-3cdcdee5-951a-4ef0-9d13-604e88d25d1d')\"\n",
              "            title=\"Suggest charts.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-3cdcdee5-951a-4ef0-9d13-604e88d25d1d button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "salary_dataset.columns"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3TB5X10XdGpZ",
        "outputId": "65323860-79a4-4d5d-8cb8-50e8f524ecb1"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['Unnamed: 0', 'YearsExperience', 'Salary'], dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "salary_dataset.drop(columns = ['Unnamed: 0'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 990
        },
        "id": "WSUVNnllbu0A",
        "outputId": "d8d4fc1b-810d-4e77-ef73-0ff3a8d360a4"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "    YearsExperience    Salary\n",
              "0               1.2   39344.0\n",
              "1               1.4   46206.0\n",
              "2               1.6   37732.0\n",
              "3               2.1   43526.0\n",
              "4               2.3   39892.0\n",
              "5               3.0   56643.0\n",
              "6               3.1   60151.0\n",
              "7               3.3   54446.0\n",
              "8               3.3   64446.0\n",
              "9               3.8   57190.0\n",
              "10              4.0   63219.0\n",
              "11              4.1   55795.0\n",
              "12              4.1   56958.0\n",
              "13              4.2   57082.0\n",
              "14              4.6   61112.0\n",
              "15              5.0   67939.0\n",
              "16              5.2   66030.0\n",
              "17              5.4   83089.0\n",
              "18              6.0   81364.0\n",
              "19              6.1   93941.0\n",
              "20              6.9   91739.0\n",
              "21              7.2   98274.0\n",
              "22              8.0  101303.0\n",
              "23              8.3  113813.0\n",
              "24              8.8  109432.0\n",
              "25              9.1  105583.0\n",
              "26              9.6  116970.0\n",
              "27              9.7  112636.0\n",
              "28             10.4  122392.0\n",
              "29             10.6  121873.0"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-c4e77b0e-f49a-4d7c-b7d4-96269a8704f2\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>YearsExperience</th>\n",
              "      <th>Salary</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1.2</td>\n",
              "      <td>39344.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1.4</td>\n",
              "      <td>46206.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1.6</td>\n",
              "      <td>37732.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2.1</td>\n",
              "      <td>43526.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2.3</td>\n",
              "      <td>39892.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>3.0</td>\n",
              "      <td>56643.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>3.1</td>\n",
              "      <td>60151.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>3.3</td>\n",
              "      <td>54446.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>3.3</td>\n",
              "      <td>64446.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>3.8</td>\n",
              "      <td>57190.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>4.0</td>\n",
              "      <td>63219.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>4.1</td>\n",
              "      <td>55795.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>4.1</td>\n",
              "      <td>56958.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>4.2</td>\n",
              "      <td>57082.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>4.6</td>\n",
              "      <td>61112.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>5.0</td>\n",
              "      <td>67939.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>5.2</td>\n",
              "      <td>66030.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>5.4</td>\n",
              "      <td>83089.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>6.0</td>\n",
              "      <td>81364.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>6.1</td>\n",
              "      <td>93941.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>6.9</td>\n",
              "      <td>91739.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>7.2</td>\n",
              "      <td>98274.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>8.0</td>\n",
              "      <td>101303.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>8.3</td>\n",
              "      <td>113813.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>8.8</td>\n",
              "      <td>109432.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>9.1</td>\n",
              "      <td>105583.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>9.6</td>\n",
              "      <td>116970.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>9.7</td>\n",
              "      <td>112636.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>10.4</td>\n",
              "      <td>122392.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>10.6</td>\n",
              "      <td>121873.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c4e77b0e-f49a-4d7c-b7d4-96269a8704f2')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-c4e77b0e-f49a-4d7c-b7d4-96269a8704f2 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-c4e77b0e-f49a-4d7c-b7d4-96269a8704f2');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-648b313b-cea2-42bb-a87b-451051e4a1c3\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-648b313b-cea2-42bb-a87b-451051e4a1c3')\"\n",
              "            title=\"Suggest charts.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-648b313b-cea2-42bb-a87b-451051e4a1c3 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(salary_dataset)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mW9Y9lIRe20p",
        "outputId": "24745814-1011-40d1-e895-7e31e89cb900"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "30"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X = salary_dataset.YearsExperience"
      ],
      "metadata": {
        "id": "S-6IqgaLdsCf"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y = salary_dataset.Salary"
      ],
      "metadata": {
        "id": "WpJOgD3teQfo"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Imports the module to split datasets.\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "metadata": {
        "id": "IWINXp_ReerJ"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = salary_dataset[['YearsExperience']].values  # Note the double brackets to keep it as DataFrame\n",
        "y = salary_dataset['Salary'].values\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
      ],
      "metadata": {
        "id": "X_gQ9TI6eqoi"
      },
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(X_train.shape)\n",
        "print(y_train.shape)\n",
        "print(X_test.shape)\n",
        "print(y_test.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "92R1_WUjiQCd",
        "outputId": "d084e918-8012-4e0c-8a41-4ec4fcabcef4"
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(24,)\n",
            "(24,)\n",
            "(6,)\n",
            "(6,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Building a model\n",
        "#Imports required TensorFlow and Keras modules.\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense"
      ],
      "metadata": {
        "id": "l72g9Qq3eyCx"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#model: The neural network model.\n",
        "model1 = Sequential()"
      ],
      "metadata": {
        "id": "fTCpKQrmfK1I"
      },
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Adds an input and hidden layer with 10 nodes and a ReLU activation function.\n",
        "model1.add(Dense(3, input_dim=1, activation='relu'))  # only 1 input: YearsExperience\n"
      ],
      "metadata": {
        "id": "nd7mS_fWfRbA"
      },
      "execution_count": 93,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Adds an output layer with 3 nodes (one for each iris species) and a softmax activation function.\n",
        "model1.add(Dense(1))  # No activation for regression\n"
      ],
      "metadata": {
        "id": "-ibZYMu7fWms"
      },
      "execution_count": 94,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Configures the model for training by setting the optimizer, loss function, and evaluation metric.\n",
        "#model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "model1.compile(optimizer='adam', loss='mean_squared_error' , metrics=['accuracy'])\n"
      ],
      "metadata": {
        "id": "UCHDO9GCfcYo"
      },
      "execution_count": 95,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Trains the model for 50 epochs using the training data and validates using the testing data.\n",
        "#history: Contains the training history, like loss and accuracy values at each epoch.\n",
        "history = model1.fit(X_train, y_train, epochs=20, batch_size=1, validation_data=(X_test, y_test))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hWVrDQudfwJl",
        "outputId": "22334085-99a9-4913-c041-b52fc08870c3"
      },
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "24/24 [==============================] - 0s 6ms/step - loss: 6271276544.0000 - accuracy: 0.0000e+00 - val_loss: 7430669824.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 2/20\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 6271262720.0000 - accuracy: 0.0000e+00 - val_loss: 7430655488.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 3/20\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 6271250432.0000 - accuracy: 0.0000e+00 - val_loss: 7430642176.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 4/20\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 6271239680.0000 - accuracy: 0.0000e+00 - val_loss: 7430630912.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 5/20\n",
            "24/24 [==============================] - 0s 4ms/step - loss: 6271229952.0000 - accuracy: 0.0000e+00 - val_loss: 7430621184.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 6/20\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 6271220224.0000 - accuracy: 0.0000e+00 - val_loss: 7430611456.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 7/20\n",
            "24/24 [==============================] - 0s 4ms/step - loss: 6271213568.0000 - accuracy: 0.0000e+00 - val_loss: 7430602752.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 8/20\n",
            "24/24 [==============================] - 0s 4ms/step - loss: 6271205376.0000 - accuracy: 0.0000e+00 - val_loss: 7430594048.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 9/20\n",
            "24/24 [==============================] - 0s 4ms/step - loss: 6271199232.0000 - accuracy: 0.0000e+00 - val_loss: 7430586368.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 10/20\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 6271193600.0000 - accuracy: 0.0000e+00 - val_loss: 7430581760.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 11/20\n",
            "24/24 [==============================] - 0s 4ms/step - loss: 6271188480.0000 - accuracy: 0.0000e+00 - val_loss: 7430576128.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 12/20\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 6271184896.0000 - accuracy: 0.0000e+00 - val_loss: 7430572544.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 13/20\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 6271182336.0000 - accuracy: 0.0000e+00 - val_loss: 7430569472.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 14/20\n",
            "24/24 [==============================] - 0s 4ms/step - loss: 6271178752.0000 - accuracy: 0.0000e+00 - val_loss: 7430565376.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 15/20\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 6271175168.0000 - accuracy: 0.0000e+00 - val_loss: 7430561792.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 16/20\n",
            "24/24 [==============================] - 0s 4ms/step - loss: 6271172608.0000 - accuracy: 0.0000e+00 - val_loss: 7430558208.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 17/20\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 6271168512.0000 - accuracy: 0.0000e+00 - val_loss: 7430554112.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 18/20\n",
            "24/24 [==============================] - 0s 4ms/step - loss: 6271164928.0000 - accuracy: 0.0000e+00 - val_loss: 7430550016.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 19/20\n",
            "24/24 [==============================] - 0s 4ms/step - loss: 6271160832.0000 - accuracy: 0.0000e+00 - val_loss: 7430546944.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 20/20\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 6271158272.0000 - accuracy: 0.0000e+00 - val_loss: 7430542848.0000 - val_accuracy: 0.0000e+00\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss, accuracy = model1.evaluate(X_test, y_test)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g_23nuquf35k",
        "outputId": "d9ec2620-ddc1-46a4-978f-2c96e437b6ac"
      },
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 32ms/step - loss: 7430141440.0000 - accuracy: 0.0000e+00\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Prints the loss and accuracy of the model on the test dataset.\n",
        "print(f\"Test Loss: {loss}\")\n",
        "print(f\"Test Accuracy: {accuracy}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MhGaGAWvlM-K",
        "outputId": "c77c052f-bc22-4a4b-e15f-3521e3aa5fa4"
      },
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Loss: 7430209024.0\n",
            "Test Accuracy: 0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "new_age = [['31']]"
      ],
      "metadata": {
        "id": "ijX040gwlYta"
      },
      "execution_count": 86,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "new_data = [[5]]  # e.g., 5 years of experience\n",
        "predicted_salary = model1.predict(new_data)\n",
        "print(f\"Predicted salary for 5 years of experience: {predicted_salary[0][0]}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IakqRVVGlwr0",
        "outputId": "45cd8e38-bc71-4a5b-a1ef-b8eeb523dddf"
      },
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 73ms/step\n",
            "Predicted salary for 5 years of experience: 2.0694949626922607\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "V2iUWXRRmCtd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "With the above mode the accuracy are not too much satisfied now again doing with some changesCertainly! The performance of a neural network on regression tasks can be influenced by various factors including the architecture, data preprocessing, and training configurations. Here's a step-by-step guide to refining your approach:\n",
        "\n",
        "### 1. Feature Scaling:\n",
        "Neural networks often perform better when input features are scaled. A common practice is to use the `StandardScaler` to scale features:\n",
        "\n",
        "```python\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Scaling features\n",
        "scaler_X = StandardScaler()\n",
        "X_train_scaled = scaler_X.fit_transform(X_train)\n",
        "X_test_scaled = scaler_X.transform(X_test)\n",
        "\n",
        "# Optionally scale the target variable if the values are large. If you do this, remember to inverse-transform predictions.\n",
        "scaler_y = StandardScaler()\n",
        "y_train_scaled = scaler_y.fit_transform(y_train.reshape(-1, 1)).flatten()\n",
        "y_test_scaled = scaler_y.transform(y_test.reshape(-1, 1)).flatten()\n",
        "```\n",
        "\n",
        "### 2. Modify Model Architecture:\n",
        "\n",
        "Sometimes, deeper networks or different architectures can capture the relationship better. Consider adding more neurons or layers.\n",
        "\n",
        "```python\n",
        "model = Sequential()\n",
        "model.add(Dense(50, input_dim=1, activation='relu'))\n",
        "model.add(Dense(50, activation='relu'))\n",
        "model.add(Dense(1, activation='linear'))\n",
        "\n",
        "model.compile(optimizer='adam', loss='mean_squared_error')\n",
        "```\n",
        "\n",
        "### 3. Train with Early Stopping:\n",
        "\n",
        "To prevent overfitting and to stop training once the validation loss stops improving, you can use Early Stopping:\n",
        "\n",
        "```python\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "\n",
        "early_stop = EarlyStopping(monitor='val_loss', patience=10)  # stop if validation loss doesn't improve for 10 epochs\n",
        "\n",
        "history = model.fit(X_train_scaled, y_train_scaled, epochs=200, batch_size=2, validation_data=(X_test_scaled, y_test_scaled), callbacks=[early_stop])\n",
        "```\n",
        "\n",
        "### 4. Evaluate Model:\n",
        "\n",
        "After training, evaluate the model's performance:\n",
        "\n",
        "```python\n",
        "loss = model.evaluate(X_test_scaled, y_test_scaled)\n",
        "print(f\"Mean Squared Error on Test Data: {loss}\")\n",
        "```\n",
        "\n",
        "### 5. Make Predictions:\n",
        "\n",
        "When making predictions, remember to inverse-transform the predicted values if you've scaled the target variable.\n",
        "\n",
        "```python\n",
        "years_experience = [[5]]\n",
        "scaled_input = scaler_X.transform(years_experience)\n",
        "predicted_salary_scaled = model.predict(scaled_input)\n",
        "predicted_salary = scaler_y.inverse_transform(predicted_salary_scaled)\n",
        "\n",
        "print(f\"Predicted salary for 5 years of experience: {predicted_salary[0][0]}\")\n",
        "```\n",
        "\n",
        "### Notes:\n",
        "\n",
        "- **Hyperparameter Tuning**: You might also consider trying out different learning rates, optimizers, or even regularizers if overfitting is a concern.\n",
        "  \n",
        "- **More Data**: If your dataset is small, gathering more data (if possible) can often help improve model performance.\n",
        "  \n",
        "- **Alternative Models**: Depending on the dataset, sometimes simpler regression models (like linear regression) or other machine learning models might perform better. Consider trying other regression models as a benchmark.\n",
        "\n",
        "Remember, iterating on the architecture, preprocessing, and hyperparameters is a key aspect of deep learning. Each dataset has its unique characteristics, and there's often no one-size-fits-all solution."
      ],
      "metadata": {
        "id": "Q_kZlwaDnZgG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Scaling features\n",
        "scaler_X = StandardScaler()\n",
        "X_train_scaled = scaler_X.fit_transform(X_train)\n",
        "X_test_scaled = scaler_X.transform(X_test)\n",
        "\n",
        "# Optionally scale the target variable if the values are large. If you do this, remember to inverse-transform predictions.\n",
        "scaler_y = StandardScaler()\n",
        "y_train_scaled = scaler_y.fit_transform(y_train.reshape(-1, 1)).flatten()\n",
        "y_test_scaled = scaler_y.transform(y_test.reshape(-1, 1)).flatten()"
      ],
      "metadata": {
        "id": "O0XBiIz-njuf"
      },
      "execution_count": 98,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model2 = Sequential()\n",
        "model2.add(Dense(50, input_dim=1, activation='relu'))\n",
        "model2.add(Dense(50, activation='relu'))\n",
        "model2.add(Dense(1, activation='linear'))\n",
        "\n",
        "model2.compile(optimizer='adam', loss='mean_squared_error' )"
      ],
      "metadata": {
        "id": "ZE_iXGp9nvGQ"
      },
      "execution_count": 110,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "\n",
        "early_stop = EarlyStopping(monitor='val_loss', patience=10)  # stop if validation loss doesn't improve for 10 epochs\n",
        "\n",
        "history = model2.fit(X_train_scaled, y_train_scaled, epochs=500, batch_size=2, validation_data=(X_test_scaled, y_test_scaled), callbacks=[early_stop])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tT0cE04pn1IR",
        "outputId": "2180ebd0-658f-4ba9-df7b-cb8e0fa64927"
      },
      "execution_count": 111,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/500\n",
            "12/12 [==============================] - 1s 22ms/step - loss: 1.1805 - val_loss: 0.6891\n",
            "Epoch 2/500\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.7686 - val_loss: 0.5028\n",
            "Epoch 3/500\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.4987 - val_loss: 0.3656\n",
            "Epoch 4/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3004 - val_loss: 0.2630\n",
            "Epoch 5/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.1711 - val_loss: 0.1696\n",
            "Epoch 6/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0847 - val_loss: 0.1106\n",
            "Epoch 7/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0399 - val_loss: 0.0755\n",
            "Epoch 8/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0267 - val_loss: 0.0615\n",
            "Epoch 9/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0226 - val_loss: 0.0566\n",
            "Epoch 10/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.0222 - val_loss: 0.0583\n",
            "Epoch 11/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.0214 - val_loss: 0.0584\n",
            "Epoch 12/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0214 - val_loss: 0.0608\n",
            "Epoch 13/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0214 - val_loss: 0.0596\n",
            "Epoch 14/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0213 - val_loss: 0.0628\n",
            "Epoch 15/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0209 - val_loss: 0.0605\n",
            "Epoch 16/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.0210 - val_loss: 0.0614\n",
            "Epoch 17/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0204 - val_loss: 0.0635\n",
            "Epoch 18/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0209 - val_loss: 0.0665\n",
            "Epoch 19/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0207 - val_loss: 0.0631\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss = model2.evaluate(X_test_scaled, y_test_scaled)\n",
        "print(f\"Mean Squared Error on Test Data: {loss}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x1ZHABw0oCU9",
        "outputId": "8880550c-0f1b-4e49-839a-9a15b0f7190d"
      },
      "execution_count": 112,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 117ms/step - loss: 0.0631\n",
            "Mean Squared Error on Test Data: 0.06313470751047134\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "years_experience = [[5]]\n",
        "scaled_input = scaler_X.transform(years_experience)\n",
        "predicted_salary_scaled = model2.predict(scaled_input)\n",
        "predicted_salary = scaler_y.inverse_transform(predicted_salary_scaled)\n",
        "\n",
        "print(f\"Predicted salary for 5 years of experience: {predicted_salary[0][0]}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nWQsN2BdoMZP",
        "outputId": "339b2e32-ee8b-409f-89cb-78529692b1b1"
      },
      "execution_count": 113,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 64ms/step\n",
            "Predicted salary for 5 years of experience: 66038.9375\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_b4I8r3KoVOe"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}